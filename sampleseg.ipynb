{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "678fc6b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x13b111f5d50>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import enum\n",
    "import time\n",
    "import random\n",
    "import multiprocessing\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchio as tio\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "from unet import UNet\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython import display\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else 'cpu'\n",
    "num_workers = 0\n",
    "batch_size = 1\n",
    "k = 5                # num k-folds\n",
    "seed = 88\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92f64a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3dc1bf4",
   "metadata": {},
   "source": [
    "Load files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6e842b97",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 75 subjects\n"
     ]
    }
   ],
   "source": [
    "file_dir = \"./dataset\"\n",
    "raw_dir = r'{0}/raw/*.nii'.format(file_dir)\n",
    "label_dir = r'{0}/label/*.nii'.format(file_dir)\n",
    "\n",
    "image_paths = sorted(glob.glob(raw_dir))\n",
    "label_paths = sorted(glob.glob(label_dir))\n",
    "assert len(image_paths) == len(label_paths)\n",
    "\n",
    "subjects = []\n",
    "subjects_full = []\n",
    "i = 0\n",
    "for (image_path, label_path) in zip(image_paths, label_paths):\n",
    "    subject = tio.Subject(\n",
    "        img = tio.ScalarImage(image_path),\n",
    "        label = tio.LabelMap(label_path),\n",
    "    )\n",
    "    subjects.append(subject)\n",
    "#     subjects_full.append(subject)\n",
    "#     if i in [5,10,15,20,25,30,40,50,60,70]:\n",
    "#         subjects.append(subject)\n",
    "#     i+=1\n",
    "# dataset_full = tio.SubjectsDataset(subjects_full)\n",
    "# print('Dataset full size:', len(dataset_full), 'subjects')\n",
    "\n",
    "dataset = tio.SubjectsDataset(subjects)\n",
    "print('Dataset size:', len(dataset), 'subjects')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8100a2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for i, subject in enumerate(dataset):\n",
    "#     print(subject.img)\n",
    "#     print(subject.label)\n",
    "#     print(\"\\n{0}\".format(i))\n",
    "#     print(subject.img.shape)\n",
    "#     print(subject.label.shape)\n",
    "\n",
    "#     affine = subject['label'][tio.AFFINE]\n",
    "#     temp = tio.Subject(\n",
    "#         ct=tio.ScalarImage(tensor=subject['img'][tio.DATA], affine=affine),\n",
    "#         truth=tio.LabelMap(tensor=subject['label'][tio.DATA], affine=affine)\n",
    "#     )\n",
    "\n",
    "#     temp.plot(figsize=(9, 8))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e02dd9",
   "metadata": {},
   "source": [
    "Preprocessing\n",
    "* Orient all images to canonical (RAS+) orientation\n",
    "* Resize images to size (256,256,128)\n",
    "* Perform histogram standardization of intensity values\n",
    "* Perform Z-normalization\n",
    "* Encode labels as '0' or '1'\n",
    "\n",
    "Data augmentation (applied at random during training only)\n",
    "* Flip along lateral axis\n",
    "* Zoom out by -10 to +10%\n",
    "* Rotate by -10° to +10°\n",
    "* Translate along each axis by -10 to +10mm\n",
    "* Downsample images by a factor of 1.5 to 5\n",
    "* Add Gaussian noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "000de0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train histogram\n",
    "landmarks_file = 'landmarks.npy'\n",
    "\n",
    "if os.path.exists(landmarks_file):\n",
    "    landmarks = np.load(landmarks_file)\n",
    "else:\n",
    "    landmarks = tio.HistogramStandardization.train(image_paths)\n",
    "    np.save(landmarks_file, landmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c1b3869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardise labels to '0' or '1'\n",
    "def binarize(x):\n",
    "    return x > 0\n",
    "\n",
    "train_transforms = tio.Compose([\n",
    "    tio.ToCanonical(),\n",
    "#     tio.Resample(2),\n",
    "    tio.CropOrPad((256,256,128), mask_name='label'),\n",
    "    tio.HistogramStandardization({'img': landmarks}),\n",
    "    tio.ZNormalization(masking_method=tio.ZNormalization.mean),\n",
    "    tio.OneOf({\n",
    "        tio.RandomAnisotropy(): 0.5,\n",
    "        tio.OneOf({\n",
    "            tio.RandomAffine(\n",
    "                scales = (0.1),\n",
    "                degrees = (10),\n",
    "                translation = (10)\n",
    "            ): 0.2,\n",
    "            tio.RandomFlip(\n",
    "                axes=('LR',)\n",
    "            ): 0.4,\n",
    "            tio.RandomNoise(): 0.4,\n",
    "        }): 0.3,\n",
    "    }),\n",
    "    tio.Lambda(binarize, types_to_apply=[tio.LABEL]),\n",
    "    tio.OneHot(),\n",
    "])\n",
    "\n",
    "test_transforms = tio.Compose([\n",
    "    tio.ToCanonical(),\n",
    "    tio.CropOrPad((256,256,128), mask_name='label'),\n",
    "    tio.HistogramStandardization({'img': landmarks}),\n",
    "    tio.ZNormalization(masking_method=tio.ZNormalization.mean),\n",
    "    tio.Lambda(binarize, types_to_apply=[tio.LABEL]),\n",
    "    tio.OneHot(),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc27adc9",
   "metadata": {},
   "source": [
    "Split train/test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "338428e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 49 images\n",
      "Validation set: 11 images\n",
      "Test set: 15 images\n"
     ]
    }
   ],
   "source": [
    "val_ratio = 0.15\n",
    "test_ratio = 0.2\n",
    "num_subjects = len(dataset)\n",
    "num_val_subjects = int(val_ratio * num_subjects)\n",
    "num_test_subjects = int(test_ratio * num_subjects)\n",
    "num_training_subjects = num_subjects - num_val_subjects - num_test_subjects\n",
    "\n",
    "training_subjects, validation_subjects, test_subjects = torch.utils.data.random_split(\n",
    "    subjects, [num_training_subjects, num_val_subjects, num_test_subjects], generator=torch.Generator().manual_seed(seed))\n",
    "\n",
    "training_set = tio.SubjectsDataset(\n",
    "    training_subjects, transform=train_transforms)\n",
    "validation_set = tio.SubjectsDataset(\n",
    "    validation_subjects, transform=test_transforms)\n",
    "test_set = tio.SubjectsDataset(\n",
    "    test_subjects, transform=test_transforms)\n",
    "\n",
    "print('Training set:', len(training_set), 'images')\n",
    "print('Validation set:', len(validation_set), 'images')\n",
    "print('Test set:', len(test_set), 'images')\n",
    "\n",
    "# splits = KFold(n_splits = k, shuffle = True, random_state = seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eeca25f",
   "metadata": {},
   "source": [
    "<!-- Split k-folds -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a31c0f",
   "metadata": {},
   "source": [
    "Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "81826d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHANNELS_DIMENSION = 1\n",
    "SPATIAL_DIMENSIONS = 2, 3, 4\n",
    "num_epochs = 3\n",
    "threshold = 0.5      # threshold for binary mask\n",
    "\n",
    "class Action(enum.Enum):\n",
    "    TRAIN = 'Training'\n",
    "    VALIDATE = 'Validation'\n",
    "    TEST = 'Testing'\n",
    "\n",
    "class EarlyStopping():\n",
    "    def __init__(self, patience = 10):\n",
    "        self.patience = patience\n",
    "        self.patience_count = 0\n",
    "        self.best_loss = float('inf')\n",
    "        self.best_epoch = -1\n",
    "        self.best_model = None\n",
    "        self.is_stopped = False\n",
    "\n",
    "    def monitor(self, curr_loss, epoch, model):\n",
    "        if curr_loss < self.best_loss:\n",
    "            print(\"Model loss improved from {0:.5f} to {1:.5f}\".format(self.best_loss, curr_loss))\n",
    "            self.save_best(curr_loss, epoch, model)\n",
    "        else:\n",
    "            self.patience_count += 1\n",
    "            if self.patience_count >= self.patience:\n",
    "                self.is_stopped = True\n",
    "                print(\"Model did not improve for {0} epochs. Best performance was achieved at epoch {1} with loss: {2:.5f}\\nStopping training early\".format(self.patience, self.best_epoch, self.best_loss))\n",
    "            else:\n",
    "                print(\"Model loss did not improve for {0}/{1} epochs\".format(self.patience_count, self.patience))\n",
    "\n",
    "        return self.is_stopped\n",
    "\n",
    "    def save_best(self, curr_loss, epoch, model):\n",
    "        self.best_loss = curr_loss\n",
    "        self.best_epoch = epoch\n",
    "        self.best_model = model\n",
    "        self.patience_count = 0\n",
    "\n",
    "    def get_best(self):\n",
    "        return self.best_epoch, self.best_model\n",
    "    \n",
    "def prepare_batch(batch, device):\n",
    "    inputs = batch['img'][tio.DATA].to(device)\n",
    "    targets = batch['label'][tio.DATA].to(device)\n",
    "    return inputs, targets\n",
    "\n",
    "def get_dice_score(output, target, epsilon=1e-9):\n",
    "    p0 = output\n",
    "    g0 = target\n",
    "    p1 = 1 - p0\n",
    "    g1 = 1 - g0\n",
    "    tp = (p0 * g0).sum(dim=SPATIAL_DIMENSIONS)\n",
    "    fp = (p0 * g1).sum(dim=SPATIAL_DIMENSIONS)\n",
    "    fn = (p1 * g0).sum(dim=SPATIAL_DIMENSIONS)\n",
    "    num = 2 * tp\n",
    "    denom = 2 * tp + fp + fn + epsilon\n",
    "    dice_score = num / denom\n",
    "    return dice_score\n",
    "\n",
    "def get_dice_loss(output, target):\n",
    "    return 1 - get_dice_score(output, target)\n",
    "\n",
    "def get_model_and_optimizer(device):\n",
    "    model = UNet(\n",
    "        in_channels=1,\n",
    "        out_classes=2,\n",
    "        dimensions=3,\n",
    "        num_encoding_blocks=3,\n",
    "        out_channels_first_layer=8,\n",
    "        normalization='batch',\n",
    "        upsampling_type='linear',\n",
    "        padding=True,\n",
    "        activation='PReLU',\n",
    "#         activation='ReLU',\n",
    "    ).to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "    return model, optimizer\n",
    "\n",
    "def run_epoch(epoch_idx, action, loader, model, optimizer):\n",
    "    is_training = action == Action.TRAIN\n",
    "    epoch_losses = []\n",
    "    epoch_accs = []\n",
    "    times = []\n",
    "    model.train(is_training)\n",
    "    for batch_idx, batch in enumerate(tqdm(loader)):\n",
    "        inputs, targets = prepare_batch(batch, device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with torch.set_grad_enabled(is_training):\n",
    "            logits = model(inputs)\n",
    "            probabilities = torch.sigmoid(logits)\n",
    "#             probabilities = torch.floor(torch.sigmoid(logits) + threshold)\n",
    "#             probabilities = F.softmax(logits, dim=CHANNELS_DIMENSION)\n",
    "            batch_losses = get_dice_loss(probabilities, targets)\n",
    "            batch_loss = batch_losses.mean()\n",
    "            if is_training:\n",
    "                batch_loss.backward()\n",
    "                optimizer.step()\n",
    "            times.append(time.time())\n",
    "            epoch_losses.append(batch_loss.item())\n",
    "            \n",
    "        batch_accuracy = get_dice_score((probabilities > threshold).float(), targets).mean()\n",
    "        epoch_accs.append(batch_accuracy.item())\n",
    "            \n",
    "    epoch_losses = np.array(epoch_losses)\n",
    "    epoch_loss = epoch_losses.mean()\n",
    "    \n",
    "    epoch_accs = np.array(epoch_accs)\n",
    "    epoch_acc = epoch_accs.mean()\n",
    "    \n",
    "    if action == Action.TEST:\n",
    "        epoch_loss_std = epoch_losses.std()\n",
    "        epoch_acc_std = epoch_accs.std()\n",
    "        print(\"{0} mean loss: {1:.5f} \\u00B1 {2:.5f}\".format(action.value, epoch_loss, epoch_loss_std))\n",
    "        print(\"{0} mean accuracy: {1:.5f} \\u00B1 {2:.5f}\".format(action.value, epoch_acc, epoch_acc_std))\n",
    "    else:\n",
    "        print(f'{action.value} mean loss: {epoch_loss:0.5f}')\n",
    "        print(f'{action.value} mean accuracy: {epoch_acc:0.5f}')\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def train(num_epochs, training_loader, validation_loader, model, optimizer, early_stopper, weights_stem):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accs = []\n",
    "    val_accs = []\n",
    "#     val_losses.append(run_epoch(0, Action.VALIDATE, validation_loader, model, optimizer))\n",
    "    for epoch_idx in range(1, num_epochs + 1):\n",
    "        print(\"\\n=== Starting epoch {0} ===\".format(epoch_idx))\n",
    "#         train_losses.append(run_epoch(epoch_idx, Action.TRAIN, training_loader, model, optimizer))\n",
    "#         val_losses.append(run_epoch(epoch_idx, Action.VALIDATE, validation_loader, model, optimizer))\n",
    "        train_loss, train_acc = run_epoch(epoch_idx, Action.TRAIN, training_loader, model, optimizer)\n",
    "        val_loss, val_acc = run_epoch(epoch_idx, Action.VALIDATE, validation_loader, model, optimizer)\n",
    "        train_losses.append(train_loss)\n",
    "        train_accs.append(train_acc)\n",
    "        val_losses.append(val_loss)\n",
    "        val_accs.append(val_acc)\n",
    "        \n",
    "        # Saves current state of model\n",
    "        torch.save(model.state_dict(), f'{weights_stem}_epoch_{epoch_idx}.pth')\n",
    "        \n",
    "        # Check early stopping\n",
    "        if early_stopper != None:\n",
    "            is_stopped = early_stopper.monitor(val_loss, epoch_idx, model.state_dict())\n",
    "            if is_stopped:\n",
    "                # Save best model\n",
    "                best_epoch, best_model = early_stopper.get_best()\n",
    "                torch.save(best_model, f'{weights_stem}_best.pth')\n",
    "                break\n",
    "    \n",
    "    print(\"Training ended at epoch {0}\".format(epoch_idx))    \n",
    "    return np.array(train_losses), np.array(train_accs), np.array(val_losses), np.array(val_accs)\n",
    "\n",
    "def test(test_loader, model, optimizer):\n",
    "    loss, accuracy = run_epoch(1, Action.TEST, test_loader, model, optimizer)\n",
    "    return loss, accuracy\n",
    "\n",
    "# training_loader = torch.utils.data.DataLoader(\n",
    "#     training_set,\n",
    "#     batch_size=training_batch_size,\n",
    "#     shuffle=True,\n",
    "#     num_workers=num_workers,\n",
    "# )\n",
    "\n",
    "# validation_loader = torch.utils.data.DataLoader(\n",
    "#     validation_set,\n",
    "#     batch_size=validation_batch_size,\n",
    "#     num_workers=num_workers,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147ad358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fold_train_loss = []\n",
    "# fold_val_loss = []\n",
    "\n",
    "# for fold, (train_idx,val_idx) in enumerate(splits.split(np.arange(len(training_set)))):\n",
    "#     print(\"\\n===== FOLD {0} ======\".format(fold + 1))\n",
    "       \n",
    "#     model, optimizer = get_model_and_optimizer(device)\n",
    "#     weights_path = 'whole_image_state_dict.pth'\n",
    "#     weights_stem = 'whole_images'\n",
    "    \n",
    "#     # Load in training & validation set for the current fold\n",
    "#     train_sampler = SubsetRandomSampler(train_idx)\n",
    "#     validation_sampler = SubsetRandomSampler(val_idx)   \n",
    "#     train_loader = DataLoader(training_set, batch_size=batch_size, sampler=train_sampler)\n",
    "#     validation_loader = DataLoader(training_set, batch_size=batch_size, sampler=validation_sampler)\n",
    "    \n",
    "#     # Train\n",
    "#     train_losses, val_losses = train(num_epochs, train_loader, validation_loader, model, optimizer, weights_stem)\n",
    "#     fold_train_loss.append(np.mean(train_losses))\n",
    "#     fold_val_loss.append(np.mean(val_losses))\n",
    "    \n",
    "#     print(\"\\n=== Fold {0}\\nTrain loss: {1}\\nVal loss: {2}\".format(fold+1, fold_train_loss[-1], fold_val_loss[-1]))\n",
    "\n",
    "# print(\"\\n===== END TRAINING =====\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0414be9b",
   "metadata": {},
   "source": [
    "Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5c08c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, optimizer = get_model_and_optimizer(device)\n",
    "weights_path = 'whole_image_state_dict.pth'\n",
    "weights_stem = 'whole_images'\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    training_set,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True,\n",
    "    num_workers = num_workers\n",
    ")\n",
    "validation_loader = torch.utils.data.DataLoader(\n",
    "    validation_set,\n",
    "    batch_size = batch_size,\n",
    "    num_workers = num_workers\n",
    ")\n",
    "early_stopper = EarlyStopping(patience = 10)\n",
    "\n",
    "train_losses, train_accs, val_losses, val_accs = train(\n",
    "    num_epochs, train_loader, validation_loader, model, optimizer, early_stopper, weights_stem\n",
    ")\n",
    "checkpoint = {\n",
    "    'train_losses': train_losses,\n",
    "    'val_losses': val_losses,\n",
    "    'weights': model.state_dict(),\n",
    "}\n",
    "torch.save(checkpoint, weights_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9aef2f",
   "metadata": {},
   "source": [
    "Plot training & validation losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a0f152",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(0)\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "plt.figure(1)\n",
    "plt.plot(train_accs, label='Training DSC')\n",
    "plt.plot(val_accs, label='Validation DSC')\n",
    "plt.title('Training and Validation DSC')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Dice Similarity Coefficient (DSC)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85547832",
   "metadata": {},
   "source": [
    "Load trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e61e088c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = UNet(\n",
    "    in_channels=1,\n",
    "    out_classes=2,\n",
    "    dimensions=3,\n",
    "    num_encoding_blocks=3,\n",
    "    out_channels_first_layer=8,\n",
    "    normalization='batch',\n",
    "    upsampling_type='linear',\n",
    "    padding=True,\n",
    "    activation='PReLU',\n",
    ").to(device)\n",
    "trained_model.load_state_dict(torch.load(\"./whole_images_best.pth\"))\n",
    "trained_model.eval()\n",
    "optimizer = torch.optim.AdamW(trained_model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178b9de6",
   "metadata": {},
   "source": [
    "Test trained model on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0b90fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_set,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    ")\n",
    "\n",
    "# test_loss = run_epoch(0, Action.VALIDATE, test_loader, model, optimizer)\n",
    "test_loss, test_acc = test(test_loader, trained_model, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f65e92a",
   "metadata": {},
   "source": [
    "Visualise predictions on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d69115f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_set,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    ")\n",
    "\n",
    "generator = iter(test_loader)\n",
    "\n",
    "for i in range(len(test_loader)):\n",
    "    print(\"Segmenting image {0}\".format(i+1))\n",
    "    batch = next(generator)\n",
    "    inputs, targets = prepare_batch(batch, device)    \n",
    "    FIRST = 0\n",
    "    FOREGROUND = 1\n",
    "    with torch.no_grad():\n",
    "#         probabilities = trained_model(inputs).softmax(dim=1)[:, FOREGROUND:].cpu()\n",
    "#         probabilities = F.softmax(trained_model(inputs), dim=CHANNELS_DIMENSION)[:, FOREGROUND:].cpu()\n",
    "        probabilities = torch.sigmoid(trained_model(inputs)).cpu()\n",
    "    \n",
    "    affine = batch['label'][tio.AFFINE][0].numpy()\n",
    "    subject = tio.Subject(\n",
    "        ct=tio.ScalarImage(tensor=batch['img'][tio.DATA][0], affine=affine),\n",
    "        truth=tio.LabelMap(tensor=batch['label'][tio.DATA][0], affine=affine),\n",
    "        predicted=tio.ScalarImage(tensor=(probabilities[0]), affine=affine),\n",
    "        predicted_binary= tio.LabelMap(tensor=(probabilities[0]>threshold), affine=affine)\n",
    "    )\n",
    "\n",
    "    score = get_dice_score((probabilities > threshold).float(), batch['label'][tio.DATA]).mean().item()\n",
    "    print(\"Dice score: {0:.5f}\".format(score))\n",
    "    # subject.plot(figsize=(9, 8), cmap_dict={'predicted': 'RdBu_r'})\n",
    "    subject.plot(figsize=(9, 8))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c93b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, subject in enumerate(test_set.dry_iter()):\n",
    "    subject['img'].save(\"./testset88/testimg{0}.nii\".format(i+1))\n",
    "    subject['label'].save(\"./testset88/testlabel{0}.nii\".format(i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff30e30d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
